---
title: "TESI NLP: LDA Analyses"
author: "Chase Antonacci"
date: "2025-10-10"
output:
  html_document:
    toc: true
    toc_float: true
    theme: united
    code_folding: hide
---

## Setup

Load all the necessary R packages for the analysis and set global options.

```{r setup, include=FALSE}
# set global options for all code chunks
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)

# load packages
library(tidyverse)
library(glmnet)
library(caret)
library(mice)
library(writexl)
library(readxl)
library(naniar)
library(VIM)
library(ggpubr)
library(patchwork)
library(ggrepel)
library(corrplot)
library(nnet)
library(reshape2)
library(xgboost)
library(Matrix)
library(dplyr)
library(data.table)
library(here)
library(rsq)
library(mixOmics)
library(psych)
library(pheatmap)
library(RColorBrewer)
library(viridis)
library(patchwork)
library(ComplexHeatmap)
library(circlize)
library(foreach)
library(doParallel)
library(colorspace)
library(ggrepel)
library(ggeffects)
```

Load data

```{r load-data}
# define the path to your data file
file_path <- here::here("data", "LDA_Participant_Level_PCA_scores.csv")
path_dx   <- here::here("data", "any_intDx_T1-TA.xlsx")


# read in data
df.lda_imputed <- read.csv(file_path)
df.dx          <- read_xlsx(path_dx)


# set appropriate variables as factors
df.lda_imputed$demo_Race.T1 <- as.factor(df.lda_imputed$demo_Race.T1)
df.lda_imputed$demo_Sex.T1  <- as.factor(df.lda_imputed$demo_Sex.T1)
```

## Elastic Net

```{r elastic-net-cv}
# ----------------------------
# Run Elastic Net Model with 5-fold Nested CV
# ----------------------------

set.seed(1)

# set up data
y <- df.lda_imputed$YSR_Internalizing_Total.T3 # DV
X <- as.matrix(df.lda_imputed[, c(2:6, 8, 11:30)]) # demographics, sumsev, 20 PCs
X <- matrix(as.numeric(X), nrow = nrow(X), dimnames = dimnames(X))
X <- scale(X)

# outer folds for nested CV
n_outer_folds <- 5
folds <- sample(rep(1:n_outer_folds, length.out = length(y)))

# grid of alpha values for tuning
alpha_grid <- seq(0, 1, by = 0.05)

# initialize performance metrics storage
cv_mse         <- c()
cv_rmse        <- c()
cv_mae         <- c()
cv_r_squared   <- c()
cv_predictions <- rep(NA, length(y))

# store best alpha and lambda per outer fold
best_alpha_folds  <- c()
best_lambda_folds <- c()

# outer CV loop
for (k in 1:n_outer_folds) {
  # split into training and test sets
  train_idx <- which(folds != k)
  test_idx  <- which(folds == k)

  X_train <- X[train_idx, ]
  y_train <- y[train_idx]
  X_test  <- X[test_idx, ]
  y_test  <- y[test_idx]

  # inner loop: tune alpha and lambda
  inner_cv_results <- data.frame()

  for (alpha_val in alpha_grid) {
    cv_model <- cv.glmnet(X_train, y_train, alpha = alpha_val, nfolds = 5)
    inner_cv_results <- rbind(
      inner_cv_results,
      data.frame(
        alpha = alpha_val,
        lambda_min = cv_model$lambda.min,
        cv_mse = min(cv_model$cvm)
      )
    )
  }

  # select best alpha/lambda from inner CV
  best_idx     <- which.min(inner_cv_results$cv_mse)
  best_alpha   <- inner_cv_results$alpha[best_idx]
  best_lambda  <- inner_cv_results$lambda_min[best_idx]

  best_alpha_folds  <- c(best_alpha_folds, best_alpha)
  best_lambda_folds <- c(best_lambda_folds, best_lambda)

  # fit model on outer train data
  final_model <- glmnet(X_train, y_train, alpha = best_alpha, lambda = best_lambda)

  # predict on outer test set
  y_pred <- predict(final_model, X_test, s = best_lambda)
  cv_predictions[test_idx] <- y_pred

  # compute performance metrics for this fold
  mse       <- mean((y_test - y_pred)^2)
  rmse      <- sqrt(mse)
  mae       <- mean(abs(y_test - y_pred))
  r_squared <- 1 - sum((y_test - y_pred)^2) / sum((y_test - mean(y_test))^2)

  cv_mse         <- c(cv_mse, mse)
  cv_rmse        <- c(cv_rmse, rmse)
  cv_mae         <- c(cv_mae, mae)
  cv_r_squared   <- c(cv_r_squared, r_squared)
}

# aggregate performance metrics
global_r_squared <- 1 - sum((y - cv_predictions)^2) / sum((y - mean(y))^2)
# this global_r_squared value should be checked against manuscript R^2
```

```{r elastic-net-importance-plot}
# ----------------------------
# Model trained on full data for feature importance
# ----------------------------

set.seed(123)

# set up data
y <- df.lda_imputed$YSR_Internalizing_Total.T3 # DV
X <- as.matrix(df.lda_imputed[, c(2:6, 8, 11:30)])
X <- matrix(as.numeric(X), nrow = nrow(X), dimnames = dimnames(X))
X <- scale(X)

alpha_grid <- seq(0, 1, by = 0.05)

# store results
cv_results <- data.frame()

for (alpha_val in alpha_grid) {
  cv_model <- cv.glmnet(X, y, alpha = alpha_val, nfolds = 5)
  cv_results <- rbind(
    cv_results,
    data.frame(
      alpha = alpha_val,
      lambda_min = cv_model$lambda.min,
      cv_mse = min(cv_model$cvm)
    )
  )
}

# select best alpha and lambda
best_idx     <- which.min(cv_results$cv_mse)
best_alpha   <- cv_results$alpha[best_idx]
best_lambda  <- cv_results$lambda_min[best_idx]

# refit final model on full dataset
final_model <- glmnet(X, y, alpha = best_alpha, lambda = best_lambda)

# ----------------------------
# Plotting: Top Predictors
# ----------------------------

coefficients <- as.data.frame(as.matrix(coef(final_model)))
coefficients$Predictors <- rownames(coefficients)
names(coefficients)[1]  <- "Coefficient"
coefficients <- coefficients[-1, , drop = FALSE] # remove intercept

coefficients <- coefficients %>%
  filter(Coefficient != 0) %>%
  slice_max(order_by = abs(Coefficient), n = 15) %>%
  mutate(Abs_Coefficient = abs(Coefficient)) %>%
  arrange(Abs_Coefficient)

# plot
pdf(here::here("figures", "LDA_EN_Predictors.pdf"), width = 7, height = 5)

ggplot(coefficients, aes(
  x = reorder(Predictors, Abs_Coefficient),
  y = Coefficient,
  fill = Coefficient > 0
)) +
  geom_bar(stat = "identity", color = "black") +
  scale_fill_manual(
    values = c("TRUE" = "#21908CFF", "FALSE" = "#FDE725FF"),
    labels = c("TRUE" = "Risk Factor", "FALSE" = "Protective"),
    name = "Association with Outcome"
  ) +
  coord_flip() +
  labs(
    title = "Key Thematic Predictors of Internalizing Problems",
    subtitle = "Standardized Coefficients from Elastic Net Model",
    x = "Predictor",
    y = "Standardized Coefficient"
  ) +
  theme_classic() +
  theme(
    axis.text.x = element_text(hjust = 1),
    plot.title = element_text(hjust = 0.5, face = "bold", size = 14),
    plot.subtitle = element_text(hjust = 0.5, face = "italic", size = 10)
  )

dev.off()


# ----------------------------
# Plotting: Predicted vs Observed Scatterplot
# ----------------------------

plot_data <- data.frame(Actual = y, Predicted = cv_predictions)
r_squared <- 1 - sum((plot_data$Actual - plot_data$Predicted)^2) / sum((plot_data$Actual - mean(plot_data$Actual))^2)
r2_label <- paste0("italic(R)^2 == ", round(r_squared, 3))

axis_min <- min(c(plot_data$Actual, plot_data$Predicted), na.rm = TRUE)
axis_max <- max(c(plot_data$Actual, plot_data$Predicted), na.rm = TRUE)

ggplot(plot_data, aes(x = Predicted, y = Actual)) +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "gray50") +
  geom_point(color = viridis(1, option = "D", begin = 0.35), alpha = 0.6) +
  geom_smooth(method = "lm", color = "#FDE725FE", se = TRUE, fill = "gray80") +
  annotate(
    "text",
    x = axis_min + (axis_max - axis_min) * 0.05,
    y = axis_max,
    label = r2_label,
    hjust = 0,
    vjust = 1,
    parse = TRUE,
    size = 5
  ) +
  labs(
    title = "Predicting Internalizing Scores from Latent Thematic Content",
    subtitle = "Predicted vs. Actual YSR Internalizing Scores",
    x = "Predicted Score (Out-of-Sample)",
    y = "Observed Score"
  ) +
  coord_fixed(ratio = 1, xlim = c(axis_min, axis_max), ylim = c(axis_min, axis_max)) +
  theme_minimal(base_size = 12) +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold"),
    plot.subtitle = element_text(hjust = 0.5, color = "gray30")
  )

ggsave(
  here::here("figures", "LDA_en_predicted_vs_observed.pdf"),
  width = 6, height = 6, units = "in"
)
```

## Model Comparison

```{r model-comparisons}
# ----------------------------
# Model YSR ~ PCs (Linear Model)
# ----------------------------

# model comparison: with and without PCs
# this matches the F-statistic in the Results text
model.pc_without <- lm(
  YSR_Internalizing_Total.T3 ~
    demo_Race.T1 +
    demo_Sex.T1 +
    demo_Age.T1 +
    demo_Parent_Edu.T1 +
    demo_INR.T1 +
    TESI_obj_sumsev.T1,
  data = df.lda_imputed
)

model.pc_with <- lm(
  YSR_Internalizing_Total.T3 ~
    demo_Race.T1 +
    demo_Sex.T1 +
    demo_Age.T1 +
    demo_Parent_Edu.T1 +
    demo_INR.T1 +
    TESI_obj_sumsev.T1 +
    PC1 +
    PC11 +
    PC12 +
    PC19 +
    PC20,
  data = df.lda_imputed
)

# results from this anova (F(5, 192)=4.027, p=.002) match the manuscript
anova(model.pc_without, model.pc_with)


# ----------------------------
# Model Diagnosis ~ PCs (Logistic Model)
# ----------------------------

model.logistic.pc <- glm(
  T3_T4_any_intDx ~
    demo_Race.T1 +
    demo_Sex.T1 +
    demo_Age.T1 +
    demo_Parent_Edu.T1 +
    demo_INR.T1 +
    TESI_obj_sumsev.T1 +
    PC1 +
    PC11 +
    PC12 +
    PC19 +
    PC20,
  data = df.lda_imputed,
  family = binomial
)
```