---
title: "TESI NLP: TF-IDF Analyses"
author: "Chase Antonacci"
date: "2025-10-10"
output:
  html_document:
    toc: true
    toc_float: true
    theme: united
    code_folding: hide
---

## Setup

Load all the necessary R packages for the analysis and set global options.

```{r setup, include=FALSE}
# set global options for all code chunks
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)

# load packages
library(tidyverse)
library(glmnet)
library(caret)
library(mice)
library(writexl)
library(readxl)
library(naniar)
library(VIM)
library(ggpubr)
library(patchwork)
library(ggrepel)
library(corrplot)
library(nnet)
library(reshape2)
library(xgboost)
library(Matrix)
library(dplyr)
library(data.table)
library(here)
library(rsq)
library(mixOmics)
library(psych)
library(pheatmap)
library(RColorBrewer)
library(viridis)
library(patchwork)
library(ComplexHeatmap)
library(circlize)
library(foreach)
library(doParallel)
library(colorspace)
library(ggrepel)
library(ggeffects)
```

Load data

```{r load-data}
# define the path to your data file
file_path <- here::here("data", "tfidf_scores_Filtered_participantOnlySpeech.csv")
path_dx      <- here::here("data", "any_intDx_T1-TA.xlsx")

# read in data
df.tfidf_imputed <- read.csv(file_path)
df.dx            <- read_xlsx(path_dx)


# set appropriate variables as factors
df.tfidf_imputed$demo_Race.T1 <- as.factor(df.tfidf_imputed$demo_Race.T1)
df.tfidf_imputed$demo_Sex.T1  <- as.factor(df.tfidf_imputed$demo_Sex.T1)
```

## Elastic Net

```{r elastic-net-cv}
# ----------------------------
# Run Elastic Net Model with 5-fold Nested CV
# ----------------------------

set.seed(123)

# set up data
y <- df.tfidf_imputed$YSR_Internalizing_Total.T3 # DV
X <- as.matrix(df.tfidf_imputed[, c(2:6, 8, 12:ncol(df.tfidf_imputed))])
X <- matrix(as.numeric(X), nrow = nrow(X), dimnames = dimnames(X))
X <- scale(X)

# outer folds for nested CV
n_outer_folds <- 5
folds <- sample(rep(1:n_outer_folds, length.out = length(y)))

# grid of alpha values for tuning
alpha_grid <- seq(0, 1, by = 0.05)

# initialize performance metrics storage
cv_mse         <- c()
cv_rmse        <- c()
cv_mae         <- c()
cv_r_squared   <- c()
cv_predictions <- rep(NA, length(y))

# store best alpha and lambda per outer fold
best_alpha_folds  <- c()
best_lambda_folds <- c()

# outer CV loop
for (k in 1:n_outer_folds) {
  # split into training and test sets
  train_idx <- which(folds != k)
  test_idx  <- which(folds == k)

  X_train <- X[train_idx, ]
  y_train <- y[train_idx]
  X_test  <- X[test_idx, ]
  y_test  <- y[test_idx]

  # inner loop: tune alpha and lambda
  inner_cv_results <- data.frame()

  for (alpha_val in alpha_grid) {
    cv_model <- cv.glmnet(X_train, y_train, alpha = alpha_val, nfolds = 5)
    inner_cv_results <- rbind(
      inner_cv_results,
      data.frame(
        alpha = alpha_val,
        lambda_min = cv_model$lambda.min,
        cv_mse = min(cv_model$cvm)
      )
    )
  }

  # select best alpha/lambda from inner CV
  best_idx     <- which.min(inner_cv_results$cv_mse)
  best_alpha   <- inner_cv_results$alpha[best_idx]
  best_lambda  <- inner_cv_results$lambda_min[best_idx]

  best_alpha_folds  <- c(best_alpha_folds, best_alpha)
  best_lambda_folds <- c(best_lambda_folds, best_lambda)

  # fit model on outer train data
  final_model <- glmnet(X_train, y_train, alpha = best_alpha, lambda = best_lambda)

  # predict on outer test set
  y_pred <- predict(final_model, X_test, s = best_lambda)
  cv_predictions[test_idx] <- y_pred

  # compute performance metrics for this fold
  mse       <- mean((y_test - y_pred)^2)
  rmse      <- sqrt(mse)
  mae       <- mean(abs(y_test - y_pred))
  r_squared <- 1 - sum((y_test - y_pred)^2) / sum((y_test - mean(y_test))^2)

  cv_mse         <- c(cv_mse, mse)
  cv_rmse        <- c(cv_rmse, rmse)
  cv_mae         <- c(cv_mae, mae)
  cv_r_squared   <- c(cv_r_squared, r_squared)
}

# aggregate performance metrics
global_r_squared <- 1 - sum((y - cv_predictions)^2) / sum((y - mean(y))^2)
# R-squared (0.076) reported in text
```

```{r elastic-net-importance-plot}
# ----------------------------
# Model trained on full data for feature importance
# ----------------------------

set.seed(123)

# set up data
y <- df.tfidf_imputed$YSR_Internalizing_Total.T3 # DV
X <- as.matrix(df.tfidf_imputed[, c(2:6, 8, 12:ncol(df.tfidf_imputed))])
X <- matrix(as.numeric(X), nrow = nrow(X), dimnames = dimnames(X))
X <- scale(X)

alpha_grid <- seq(0, 1, by = 0.05)

# store results
cv_results <- data.frame()

for (alpha_val in alpha_grid) {
  cv_model <- cv.glmnet(X, y, alpha = alpha_val, nfolds = 5)
  cv_results <- rbind(
    cv_results,
    data.frame(
      alpha = alpha_val,
      lambda_min = cv_model$lambda.min,
      cv_mse = min(cv_model$cvm)
    )
  )
}

# select best alpha and lambda
best_idx     <- which.min(cv_results$cv_mse)
best_alpha   <- cv_results$alpha[best_idx]
best_lambda  <- cv_results$lambda_min[best_idx]

# refit final model on full dataset
final_model <- glmnet(X, y, alpha = best_alpha, lambda = best_lambda)

# ----------------------------
# Plotting: Top Predictors
# ----------------------------

coefficients <- as.data.frame(as.matrix(coef(final_model)))
coefficients$Predictors <- rownames(coefficients)
names(coefficients)[1]  <- "Coefficient"
coefficients <- coefficients[-1, , drop = FALSE] # remove intercept

coefficients <- coefficients %>%
  filter(Coefficient != 0) %>%
  slice_max(order_by = abs(Coefficient), n = 15) %>%
  mutate(Abs_Coefficient = abs(Coefficient)) %>%
  arrange(Abs_Coefficient)

# plot
pdf(here::here("figures", "TFIDF_EN_Predictors.pdf"), width = 7, height = 5)

ggplot(coefficients, aes(
  x = reorder(Predictors, Abs_Coefficient),
  y = Coefficient,
  fill = Coefficient > 0
)) +
  geom_bar(stat = "identity", color = "black") +
  scale_fill_manual(
    values = c("TRUE" = "#21908CFF", "FALSE" = "#FDE725FF"),
    labels = c("TRUE" = "Risk Factor", "FALSE" = "Protective"),
    name = "Association with Outcome"
  ) +
  coord_flip() +
  labs(
    title = "Top Word-Level Predictors of Internalizing Problems",
    subtitle = "Standardized Coefficients from Elastic Net Model",
    x = "Predictor",
    y = "Standardized Coefficient"
  ) +
  theme_classic() +
  theme(
    axis.text.x = element_text(hjust = 1),
    plot.title = element_text(hjust = 0.5, face = "bold", size = 14),
    plot.subtitle = element_text(hjust = 0.5, face = "italic", size = 10)
  )

dev.off()


# ----------------------------
# Plotting: Predicted vs Observed Scatterplot
# ----------------------------

plot_data <- data.frame(Actual = y, Predicted = cv_predictions)
r_squared_val <- 1 - sum((plot_data$Actual - plot_data$Predicted)^2) / 
                       sum((plot_data$Actual - mean(plot_data$Actual))^2)
r2_label <- paste0("italic(R)^2 == ", round(r_squared_val, 3))

axis_min <- min(c(plot_data$Actual, plot_data$Predicted), na.rm = TRUE)
axis_max <- max(c(plot_data$Actual, plot_data$Predicted), na.rm = TRUE)

ggplot(plot_data, aes(x = Predicted, y = Actual)) +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "gray50") +
  geom_point(color = viridis(1, option = "D", begin = 0.35), alpha = 0.6) +
  geom_smooth(method = "lm", color = "#FDE725FE", se = TRUE, fill = "gray80") +
  annotate(
    "text",
    x = axis_min + (axis_max - axis_min) * 0.05,
    y = axis_max,
    label = r2_label,
    hjust = 0,
    vjust = 1,
    parse = TRUE,
    size = 5
  ) +
  labs(
    title = "Predictive Performance of a Word-Level TF-IDF Model",
    subtitle = "Predicted vs. Actual YSR Internalizing Scores",
    x = "Predicted Score (Out-of-Sample)",
    y = "Observed Score"
  ) +
  coord_fixed(ratio = 1, xlim = c(axis_min, axis_max), ylim = c(axis_min, axis_max)) +
  theme_minimal(base_size = 12) +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold"),
    plot.subtitle = element_text(hjust = 0.5, color = "gray30")
  )

ggsave(
  here::here("figures", "TFIDF_en_predicted_vs_observed.pdf"),
  width = 6, height = 6, units = "in"
)
```

## Bivariate correlations between TF-IDF words and YSR score

```{r bivariate-correlations}
# --- 1. Define Variables ---
df              <- df.tfidf_imputed
outcome_var     <- "YSR_Internalizing_Total.T3"
predictor_cols  <- 12:ncol(df)
predictor_names <- colnames(df)[predictor_cols]

# --- 2. Calculate Correlations ---
correlation_results <- lapply(predictor_names, function(word) {
  test_result <- tryCatch(
    {
      cor.test(df[[word]], df[[outcome_var]], method = "pearson")
    },
    error = function(e) {
      NULL
    }
  )

  if (!is.null(test_result)) {
    return(data.frame(
      Word = word,
      Correlation = test_result$estimate,
      P_Value = test_result$p.value
    ))
  } else {
    return(NULL)
  }
})

# --- 3. Combine, Correct, and Sort ---
all_correlations <- do.call(rbind, correlation_results)

sorted_correlations_fdr <- all_correlations %>%
  mutate(P_Value_FDR = p.adjust(P_Value, method = "BH")) %>%
  arrange(desc(abs(Correlation)))
```

## PCA on TF-IDF scores

```{r pca-analysis}
# ----------------------------
# Run PCA
# ----------------------------
df.tfidf_pca <- df.tfidf_imputed[, 12:ncol(df.tfidf_imputed)]
rownames(df.tfidf_pca) <- df.tfidf_imputed$ELS_ID

pca_result <- prcomp(df.tfidf_pca, center = TRUE, scale. = TRUE)

# ----------------------------
# Extract PC Scores
# ----------------------------
pc_scores_with_ids <- pca_result$x %>%
  as.data.frame() %>%
  dplyr::select(PC1, PC2, PC3) %>%
  rownames_to_column("ELS_ID") %>%
  mutate(ELS_ID = as.character(ELS_ID))

# merge with original df
df_final_with_pcs <- df.tfidf_imputed %>%
  mutate(ELS_ID = as.character(ELS_ID)) %>%
  left_join(pc_scores_with_ids, by = "ELS_ID")
```

```{r pca-scree-plot, fig.width=7, fig.height=5}
# ----------------------------
# Scree Plot of PCs
# ----------------------------
eigenvalues <- pca_result$sdev^2
variance_explained <- eigenvalues / sum(eigenvalues)

scree_data <- tibble(
  Component = 1:length(eigenvalues),
  Eigenvalue = eigenvalues,
  Variance_Explained = variance_explained
) %>%
  filter(Component <= 10)

ggplot(scree_data, aes(x = Component, y = Eigenvalue)) +
  geom_line(color = "gray60", linewidth = 1) +
  geom_point(size = 4, color = viridis(1, option = "D", begin = 0.35)) +
  geom_hline(yintercept = 1, linetype = "dashed", color = "red", alpha = 0.6) +
  annotate(
    "segment",
    x = 3, xend = 3,
    y = 0.5, yend = scree_data$Eigenvalue[3] - 2,
    arrow = arrow(length = unit(0.2, "cm")),
    color = "gray30"
  ) +
  annotate(
    "text",
    x = 1.4, y = 6,
    label = "Elbow indicates\n3 components",
    hjust = 0,
    color = "gray30",
    fontface = "italic",
    size = 3.5
  ) +
  labs(
    title = "Scree Plot of Principal Components",
    subtitle = "Elbow at the third component suggests a three-factor solution",
    x = "Principal Component Number",
    y = "Eigenvalue (Variance Explained)"
  ) +
  scale_x_continuous(breaks = 1:10) +
  theme_minimal(base_size = 14) +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold"),
    plot.subtitle = element_text(hjust = 0.5, color = "gray30", size = 11),
    panel.grid.minor = element_blank()
  )

ggsave(
  here::here("figures", "tfidf_pca_scree_plot.pdf"),
  width = 7, height = 5, units = "in"
)
```

```{r pca-loadings-plot, fig.width=8, fig.height=4}
# ----------------------------
# PC Loadings Plot
# ----------------------------
top_n <- 10 # number of top features to display

top_features_per_pc <- pca_result$rotation %>%
  as.data.frame() %>%
  dplyr::select(PC1, PC2, PC3) %>%
  rownames_to_column("Feature") %>%
  pivot_longer(
    cols = c(PC1, PC2, PC3),
    names_to = "PC",
    values_to = "Loading"
  ) %>%
  group_by(PC) %>%
  slice_max(order_by = abs(Loading), n = top_n) %>%
  ungroup() %>%
  mutate(PC_Label = factor(PC,
    levels = c("PC1", "PC2", "PC3"),
    labels = c(
      "PC1: Function Words",
      "PC2: Interpersonal Focus",
      "PC3: Visceral Experience"
    )
  ))

pca_loading_plot <- ggplot(
  top_features_per_pc,
  aes(x = Loading, y = reorder(Feature, Loading), fill = Loading)
) +
  geom_col(alpha = 0.8) +
  facet_wrap(~PC_Label, scales = "free_y") +
  labs(
    title = paste0("Top ", top_n, " Word Loadings for the First Three Principal Components"),
    x = "Loading Strength",
    y = NULL
  ) +
  scale_fill_viridis_c(option = "C") +
  theme_minimal(base_size = 12) +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold", margin = margin(b = 15)),
    axis.title.x = element_text(margin = margin(t = 10)),
    legend.position = "none",
    strip.text = element_text(size = 11)
  )

ggsave(
  here::here("figures", "TFIDF_PCA_Loading.pdf"),
  plot = pca_loading_plot,
  width = 8,
  height = 4,
  units = "in"
)
```

```{r pca-models-linear}
# ----------------------------
# Model YSR ~ PCs
# ----------------------------
model.pc <- lm(
  YSR_Internalizing_Total.T3 ~
    demo_Race.T1 +
    demo_Sex.T1 +
    demo_Age.T1 +
    demo_Parent_Edu.T1 +
    demo_INR.T1 +
    TESI_obj_sumsev.T1 +
    PC1 +
    PC2 +
    PC3,
  data = df_final_with_pcs
)
# results (B=0.258, p=.011) reported in text

# with sex interaction
model.pc_sex <- lm(
  YSR_Internalizing_Total.T3 ~
    demo_Race.T1 +
    demo_Sex.T1 +
    demo_Age.T1 +
    demo_Parent_Edu.T1 +
    demo_INR.T1 +
    TESI_obj_sumsev.T1 +
    PC1 * demo_Sex.T1 +
    PC2 +
    PC3,
  data = df_final_with_pcs
)

# model comparison
model.pc_without <- lm(
  YSR_Internalizing_Total.T3 ~
    demo_Race.T1 +
    demo_Sex.T1 +
    demo_Age.T1 +
    demo_Parent_Edu.T1 +
    demo_INR.T1 +
    TESI_obj_sumsev.T1,
  data = df_final_with_pcs
)

model.pc_with <- lm(
  YSR_Internalizing_Total.T3 ~
    demo_Race.T1 +
    demo_Sex.T1 +
    demo_Age.T1 +
    demo_Parent_Edu.T1 +
    demo_INR.T1 +
    TESI_obj_sumsev.T1 +
    PC1,
  data = df_final_with_pcs
)
# anova(model.pc_without, model.pc_with)
# results (F(1, 192)=6.324, p = .013) reported in text
```

```{r pca-plot-scatter, fig.width=8, fig.height=5}
# ----------------------------
# YSR ~ PC1 Correlation Scatterplot
# ----------------------------
ggplot(df_final_with_pcs, aes(x = PC1, y = YSR_Internalizing_Total.T3)) +
  geom_point(color = viridis(1, option = "D", begin = 0.35), alpha = 0.6) +
  geom_smooth(method = "lm", color = "#FDE725FF", se = TRUE, fill = "gray80") +
  stat_cor(
    method = "pearson",
    aes(label = paste0(
      ..r.label..,
      "*', '*",
      ifelse(..p.. < 0.001,
        "italic(p)~`<`~.001",
        paste0("italic(p)~`=`~", sprintf("%.3f", ..p..))
      )
    )),
    label.x.npc = 0.05,
    label.y.npc = 0.95,
    hjust = 0,
    size = 5
  ) +
  labs(
    title = "Association Between Function Word Usage and Internalizing Problems",
    subtitle = "PC1 captures a narrative style high in function word use",
    x = "PC1 Score (Function Words)",
    y = "YSR Internalizing Score"
  ) +
  theme_minimal(base_size = 12) +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold"),
    plot.subtitle = element_text(hjust = 0.5, color = "gray30", size = 10),
    panel.grid.minor = element_blank()
  )

ggsave(
  here::here("figures", "tfidf_pca_scatter.pdf"),
  width = 8, height = 5, units = "in"
)
```

```{r pca-models-logistic}
# ----------------------------
# Model Diagnosis ~ PCs (logistic)
# ----------------------------

model.logistic.pc <- glm(
  T3_T4_any_intDx ~
    demo_Race.T1 +
    demo_Sex.T1 +
    demo_Age.T1 +
    demo_Parent_Edu.T1 +
    demo_INR.T1 +
    TESI_obj_sumsev.T1 +
    PC1,
  data = df_final_with_pcs,
  family = binomial
)

# get odds ratios for interpretation
odds_ratios <- exp(coef(model.logistic.pc))
conf_intervals_or <- exp(confint(model.logistic.pc))

results_table <- data.frame(
  Odds_Ratio = odds_ratios,
  CI_Lower = conf_intervals_or[, 1],
  CI_Upper = conf_intervals_or[, 2]
)
```

```{r pca-plot-logistic-prob, fig.width=7, fig.height=5}
# ----------------------------
# Predicted Probability Plot
# ----------------------------

predicted_probs <- ggpredict(model.logistic.pc, terms = "PC1")

ggplot(predicted_probs) +
  geom_line(aes(x = x, y = predicted), color = "#21908CFF", linewidth = 1.2) +
  geom_ribbon(aes(x = x, ymin = conf.low, ymax = conf.high), alpha = 0.2, fill = "gray60") +
  geom_rug(
    data = df_final_with_pcs,
    aes(x = PC1, color = as.factor(T3_T4_any_intDx)),
    sides = "b",
    alpha = 0.7,
    length = unit(0.04, "npc")
  ) +
  scale_color_manual(
    name = "Participant Status",
    values = c("1" = "red", "0" = "gray30"),
    labels = c("1" = "Diagnosis", "0" = "No Diagnosis")
  ) +
  labs(
    title = "Probability of Future Diagnosis by Function Word Usage",
    subtitle = "Predicted probability based on PC1, controlling for covariates",
    x = "PC1 Score (Function Words)",
    y = "Predicted Probability of Diagnosis"
  ) +
  scale_y_continuous(labels = scales::percent_format(), limits = c(0, NA)) +
  theme_minimal(base_size = 12) +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold"),
    plot.subtitle = element_text(hjust = 0.5, color = "gray30", size = 10),
    panel.grid.minor = element_blank(),
    legend.position = "bottom"
  )

ggsave(
  here::here("figures", "tfidf_pca_dx.pdf"),
  width = 7, height = 5, units = "in"
)
```

